<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>1471-2202-10-14.fm</title>
<meta name="Author" content="abdulkadir.sufi"/>
<meta name="Creator" content="FrameMaker 8.0"/>
<meta name="Producer" content="Acrobat Distiller 8.1.0 (Windows)"/>
<meta name="CreationDate" content=""/>
</head>
<body>
<pre>
BMC Neuroscience

BioMed Central

Open Access

Research article

Orienting asymmetries and lateralized processing of sounds in
humans
Julia Fischer*1, Christoph Teufel1,2, Matthis Drolet1, Annika Patzelt1,
Rudolf Rübsamen3, D Yves von Cramon4 and Ricarda I Schubotz4,5
Address: 1Research Group Cognitive Ethology, German Primate Center and University of Göttingen, Kellnerweg 4, 37077 Göttingen, Germany,
2Department of Experimental Psychology, University of Cambridge, Cambridge, UK, 3Institute of Biology-II, University of Leipzig, Germany, 4Max
Planck Institute for Human Cognitive and Brain Sciences, Department of Neurology, Leipzig, Germany and 5Max Planck Institute for Neurological
Research, Motor Cognition Group, Köln, Germany
Email: Julia Fischer* - fischer@cog-ethol.de; Christoph Teufel - c.teufel@psychol.cam.ac.uk; Matthis Drolet - matthisdrolet@gmail.com;
Annika Patzelt - apatzelt@dpz.eu; Rudolf Rübsamen - rueb@rz.uni-leipzig.de; D Yves von Cramon - cramon@nf.mpg.de;
Ricarda I Schubotz - schubotz@nf.mpg.de
* Corresponding author

Published: 24 February 2009
BMC Neuroscience 2009, 10:14

doi:10.1186/1471-2202-10-14

Received: 22 October 2008
Accepted: 24 February 2009

This article is available from: http://www.biomedcentral.com/1471-2202/10/14
© 2009 Fischer et al; licensee BioMed Central Ltd.
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0),
which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.

Abstract
Background: Lateralized processing of speech is a well studied phenomenon in humans. Both
anatomical and neurophysiological studies support the view that nonhuman primates and other
animal species also reveal hemispheric differences in areas involved in sound processing. In recent
years, an increasing number of studies on a range of taxa have employed an orienting paradigm to
investigate lateralized acoustic processing. In this paradigm, sounds are played directly from behind
and the direction of turn is recorded. This assay rests on the assumption that a hemispheric
asymmetry in processing is coupled to an orienting bias towards the contralateral side. To examine
this largely untested assumption, speech stimuli as well as artificial sounds were presented to 224
right-handed human subjects shopping in supermarkets in Germany and in the UK. To verify the
lateralized processing of the speech stimuli, we additionally assessed the brain activation in
response to presentation of the different stimuli using functional magnetic resonance imaging
(fMRI).
Results: In the naturalistic behavioural experiments, there was no difference in orienting
behaviour in relation to the stimulus material (speech, artificial sounds). Contrary to our
predictions, subjects revealed a significant left bias, irrespective of the sound category. This left bias
was slightly but not significantly stronger in German subjects. The fMRI experiments confirmed that
the speech stimuli evoked a significant left lateralized activation in BA44 compared to the artificial
sounds.
Conclusion: These findings suggest that in adult humans, orienting biases are not necessarily
coupled with lateralized processing of acoustic stimuli. Our results – as well as the inconsistent
orienting biases found in different animal species – suggest that the orienting assay should be used
with caution. Apparently, attention biases, experience, and experimental conditions may all affect
head turning responses. Because of the complexity of the interaction of factors, the use of the
orienting assay to determine lateralized processing of sound stimuli is discouraged.

Page 1 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

Background
The French neuroanatomist and anthropologist Paul
Broca was the first to present evidence that the circuits
involved in speech production could be localized in a relatively distinct area [1]. Broca's findings also pointed
towards a link between speech impairment and damage to
the left side of the brain, and in the meantime, the observation of left hemispheric dominance in both production
and perception of the semantic and syntactical aspects,
and a right hemisphere dominance for the processing of
prosodic and emotional aspects of speech, has attained
the status of a firmly supported scientific finding [2,3].
More recently, comparative research has shown that lateralized processing of acoustic stimuli is not restricted to
humans [4-6]. Most important for the current topic, a
number of studies involving neuroanatomical, physiological and behavioural methods revealed hemispheric lateralization in the processing of species-specific sounds in
non-human primates analogous to the processing of
speech stimuli in humans (for a review see [5]). Japanese
macaques, Macaca fuscata, for instance, revealed a right ear
advantage – corresponding to a left hemispheric dominance – when they were trained to discriminate communicatively important features in their species-specific
sounds [7]. After lesioning of the left superior temporal
gyrus (STG), members of the same species showed a
stronger postoperative decrement in the discrimination of
species-specific calls than after an equivalent lesioning of
the right STG. Finally, measuring local cerebral metabolic
activity to directly detect auditory processing asymmetries
in rhesus monkeys (M. mulatta), Poremba and colleagues
[8] found a greater amount of activity in the left temporal
pole in response to species-specific calls as opposed to any
other sounds (see also [8] for a critical expansion).
However, many of these methodological approaches are
either invasive or require extensive training of the subjects. Therefore, a simple assay introduced by Hauser and
Andersson [9] has gained considerable attention and led
to a series of follow-up studies in other species. This assay
was first used on a population of free-ranging rhesus monkeys living on the island of Cayo Santiago. In this paradigm, a speaker was hidden directly behind subjects that
were sitting in front of a food dispenser. When the animals were aligned with the speaker, either a species-specific vocalization or a bird alarm call was played and the
direction of the head-turn response (with the right ear or
left ear leading) was recorded. In the following, we will
refer to this experimental design as the 'head turning paradigm'. These experiments and a number of follow-up
studies revealed that the monkeys preferentially turned
with their right ear leading when exposed to species-specific calls, and with their left ear leading in response to
hetero-specific or manipulated species-specific calls [912]. This finding was interpreted as a demonstration of a

http://www.biomedcentral.com/1471-2202/10/14

left-hemispheric processing bias for species-specific vocalisations and a right-hemispheric bias for hetero-specific
calls. While a left-hemispheric dominance for processing
of species-specific calls is in line with the majority of neurophysiological and neuroanatomical research, none of
these studies showed a right-hemispheric dominance for
hetero-specific sounds (but see [13,14]).
More importantly, a number of recent studies employing
the head turning paradigm in other species suggested a
more complex pattern (see [15] for a review). Vervet monkeys, Chlorocebus aethiops, for example, were reported to
have a left-turning (right-hemispheric) bias for processing
species-specifics' calls [16] and no bias for hetero-specific
sounds, while neither Barbary macaques, M. sylvanus, [15]
nor mouse lemurs, Microcebus murinus, [17] turned preferentially with either their right or left ear leading in
response to playback of species-specific or hetero-specific
sounds. Interestingly though, the mouse lemurs showed
sex differences in orienting behaviour, but only in
response to specific calls [17]. Finally, analogous to rhesus
monkeys, California sea lions, Zalophus californianus,
turned preferentially with their right ear leading in
response to species-specific calls but by contrast to rhesus
monkeys showed no bias in response to hetero-specific
calls [18], while dogs turned with their right ear leading to
conspecifics' vocalizations and with their left ear leading
when presented with thunder [19] in an experimental setting where these sounds were played from both sides
simultaneously.
The inconsistent pattern of findings using the orienting
paradigm in different species might be a result of an unexpectedly complex pattern of the phylogenetic distribution
of hemispheric lateralization in closely related species.
Alternatively, these findings might point towards methodological problems of the orienting paradigm, a possibility
that appears to be supported by within-species inconsistencies between the orienting paradigm and more established measures of lateralized acoustic processing (see
[15] for a detailed discussion). It thus seems vital to substantiate the connection between turning bias and lateralised processing before the orienting paradigm can be used
to explore brain lateralization.
The purpose of the present study was to examine the link
between orienting asymmetries and hemispheric lateralization in the processing of sounds in adult humans.
Humans constitute an ideal test case as the lateralized
processing of speech is firmly established (see above). To
our knowledge, this is the first study that systematically
scrutinises whether such lateralized processing indeed
leads to reliable orienting asymmetries, as postulated by
previous studies in nonhuman primates and other animals. To examine this link, we combined naturalistic

Page 2 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

http://www.biomedcentral.com/1471-2202/10/14

behavioural experiments with neuroimaging techniques.
The behavioural experiments were conducted in a fashion
that approximated the test conditions used in the animal
studies. That is, each subject was tested only once in a 'real
life' situation where the subject was unaware of the purpose and the occurrence of the experiment. Speech stimuli
and artificial sounds were played directly behind subjects
shopping in a supermarket. The first set of these experiments was conducted in Germany. In light of the results
(see below), we ran a second set of experiments in the UK
to explore the possible influence of experience in a left vs.
a right driving country. Functional magnetic resonance
imaging (fMRI) was used on a separate population in Germany to validate the lateralized processing of the Speech
stimuli employed in the naturalistic experiment in a German population.
Based on previous research, we expected a left hemispheric dominance for the processing of the speech stimuli and bilateral activation for the artificial sounds in the
fMRI experiments. In accordance with the underlying
assumptions of the orienting paradigm, and the left-hemisphere dominance for speech processing, we predicted
that (right-handed) subjects would preferentially turn
with the right ear leading when presented with human
speech sounds, while they should reveal no bias in
response to the presentation of artificial sounds.
Although the fMRI data confirmed the assumption of
stronger left hemisphere activation for the speech sounds
and bilateral activation for artificial sounds, the naturalistic behavioural experiments revealed no difference in orienting behaviour in relation to the stimulus category
(Speech vs. Artificial sounds). Overall, subjects turned left
more frequently, and this tendency was slightly, but not
significantly stronger in German subjects.

Results
Behavioural data
For the German sample, significantly more people turned
left than right after playback of the speech sounds (Figure
1; binomial test, N = 61, corrected p* = 0.004; see also
Table 1: Orienting responses in relation to stimulus category and
country

Country

Stimulus

Left

Right

Total

D

Speech

44

17

61

Artificial

38

25

63

Speech

20

20

40

Artificial

33

27

60

UK

Table 1). Upon presentation of the artificial sounds, the
tendency to turn left did not reach significance (binomial
test, N = 63, p* = 0.390). There was no significant difference between the two conditions in the propensity to turn
left (Fisher's exact test, N = 124, χ2 = 1.931, df = 1, p =
0.187). To examine a possible influence of experience on
orienting behaviour in a left vs. a right-driving country, we
initiated a second set of experiments in the UK. We used
the same artificial sounds, but English speech stimuli.
Subjects revealed no significant orienting bias in either of
the conditions (Figure 1; binomial test, N = 40 for Speech
and N = 60 for Artificial, both p* = 1.0). A multinomial
logistic regression with the factors stimulus category,
country and gender revealed a slight but not significant
influence of the country where the experiment was conducted, no other significant effects and no significant
interactions (all p for interactions > 0.2; Table 2).
These results stand in stark contrast to our prediction of a
right turning bias in response to speech that was based on
the assumption of a specific coupling of lateralized
processing of stimuli and a turning bias. To corroborate
the lateralized processing of the sound stimuli used in the
experiments, we therefore used functional magnetic resonance imaging to assess the processing of the sounds. For
logistic reasons, we restricted this analysis to a comparison of the German Speech sounds vs. the Artificial sounds
in a German study population.
FMRI Experiment
Behavioural Performance
We presented different sounds in a (sham) sound localization task in which participants were asked to judge
whether the sound was presented "from the left or right"
by manipulating inter-aural time differences (ITDs). Our
analysis was restricted to those trials where sounds
revealed no ITD (and thus simulated a midline soundsource or 0° position). Subjects were naïve to the fact that
such trials also occurred.

Responses to auditory stimuli presented from the 0° position were slightly biased towards the right in both condiTable 2: Likelihood ratio tests and parameter estimates for main
effects on orienting behaviour
2
χ1 p

Factor

-2 LL

Wald

B

s.e.

Stimulus Category

0.50

1

0.479

0.500

-0.198

0.280

Country

3.44

1

0.064

3.426

0.516

0.279

Gender

2.07

1

0.150

2.080

0.426

0.295

Results are based on a multinomial regression. Since there were no
significant interactions, these were removed from the final model. -2
LL = -2 log-likelihood

Page 3 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

http://www.biomedcentral.com/1471-2202/10/14

Figure 1
Orienting biases in head turning experiment
Orienting biases in head turning experiment. Percent left turns in response to playback of Speech and Artificial sounds
in Germany and the UK, respectively. In response to speech sounds, German subjects revealed a significant left bias (* corrected p = 0.004). Orienting responses in the other three conditions were not significantly different from chance.

tions (56.3% Speech, 57.6% Artificial), but these biases
were not significantly different from chance: for Speech,
14 subjects showed a right (R) bias, seven a left (L) bias,
and one subject no bias (binomial test N = 21, p = 0.189);
in the Artificial condition, 14 subjects showed a R bias,
five a L bias, and three no bias (N = 21, p = 0.064). A
repeated-measured ANOVA with the within-subject factor
stimulus and the between-subjects factor Gender showed
no main effect of the Stimulus category (F(1, 18) = 0.073,
p = 0.974), no influence of Gender (p = 0.6) and no significant interaction between Stimulus × Gender (p =
0.506).
Contrasted with the Visual control condition, each auditory location task elicited overlapping activations in a network comprising superior temporal regions and the
parietal operculum, with maximal activation in the left
and right gyrus of Heschl. Direct contrasts revealed activations in the left Brodmann Area (BA) 44 (Broca's Area)
(Talairach coordinates x/y/z = -41/16/21 with z-max 4.3,
1998 mm3 = 74 voxels) and in the superior temporal gyrus
bilaterally (-53/-20/0 z-max 5.0, 10746 mm3 = 398 voxels
and 52/-32/9 z-max 4.5, 5670 mm3 = 210 voxels) for
Speech in contrast to Artificial sounds (Figure 2). When
contrasting Speech stimuli virtually presented 0° from
behind with those virtually presented 10° or 20° from
behind, activation was found in Broca's Area (-42/13/12,

z-max 4.6, 1944 mm3 = 72 voxels). This effect was exclusively found for Speech sounds.

Discussion
Contrary to our predictions, we found no significant difference of the orienting behaviour in relation to the stimulus category despite the fact that we did observe
differential lateralized brain activation as a response to
the different stimuli. Specifically, the left BA 44 (Broca's
area) and frontal operculum showed a higher activation
for Speech in contrast to Artificial sounds. In combination
with the naturalistic behavioural experiments, these
results indicate that in humans, hemispheric lateralization in the processing of sounds is not necessarily linked
to a preferential contra-lateral orienting response.
Across the categories, subjects in the naturalistic behavioural experiment revealed a left turning bias. This bias
was more pronounced in the German population, and
attained significance in response to Speech stimuli. The
source of this strong tendency to turn left after presentation of the speech sounds and the tendency of the English
sample to show a weaker left turning bias is presently
unclear. One possibility is that the orienting behaviour is
governed by a tendency to shift attention to the left side in
spatial tasks – in line with the assumption of a right hemisphere dominance in this domain [20,21]. On the other

Page 4 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

http://www.biomedcentral.com/1471-2202/10/14

mal studies (> 75% in rhesus monkeys, [9]), we should
still have seen an effect. This was not the case.
The fMRI data clearly demonstrated a lateralized processing of the speech stimuli used in the experiments. As an
exclusive finding for Speech sounds, activity in Broca's
Area was further boosted when Speech sounds were presented directly from behind. We take this to reflect a differential processing of the stimulus material in the
different conditions and a further evidence for lateralized
brain responses to speech. Obviously, the experimental
conditions in the naturalistic setting differed from the situation during image acquisition in the scanner, where
subjects were instructed to pay attention to a particular
feature (sound location) and where they were exposed to
repeated presentations. Both experimental modifications
were deemed necessary to allow for the acquisition of
imaging data without running the danger that brain activation simply reflects the default state of brain activity
[28,29]. Irrespective of these modifications, the imaging
data clearly show that the Speech stimuli used in the
experiments evoked lateralized processing while the Artificial stimuli did not. We are thus able to rule out the possibility that the lack of stimulus-dependent orienting
behaviour was due to a lack of lateralized processing of
the Speech stimuli.
Figure 2
Activation patterns in the fMRI Experiment
Activation patterns in the fMRI Experiment. Groupaveraged (n = 22) statistical maps of significantly activated
areas. Direct task contrasts revealed stimulus specific activations for Speech as compared to Artificial sounds in Broca's
Area and in both auditory cortices. For sounds presented
from the 0° position as compared to those presented from
10° or 20° from the right or the left, only Speech sounds displayed activation increase in Broca's Area.

hand, when participants were instructed to attend to the
sound source, they revealed a bias to attribute sounds
coming from the 0° position as coming from the right,
suggesting that spatial orientation is modulated by context [22-26]. Further behavioural experiments [see Additional file 1] suggest that this tendency is not restricted to
the experimental situation but related to the instruction to
localize the sound source. Thus, the results suggest that
orienting responses can also be affected by the specific
demands of the task employed. For practical reasons, we
had to rely on self-report data regarding handedness.
Obviously, this may introduce a certain degree of error,
since different assessments of handedness may come to
different conclusions [27]. If lateralized processing of
speech, however, would lead to an asymmetry in orienting behavior equivalent to that found in some of the ani-

Taken together, our results suggest that lateralized
processing of sounds does not inevitably lead to orienting
biases under experimental conditions like in this study or
the other studies that employed this paradigm on (relatively) free ranging animals. The comparison of the results
in the naturalistic setting and under experimental conditions suggests that the task demands may affect the orienting behaviour, and it might be possible that further factors
influence orienting responses. We are also aware that our
experimental situation in the supermarket was not identical to the one employed for the animals where sounds
were typically presented from a hidden speaker, and not
from a conspecifics carrying one. Possibly, under different
experimental conditions, a weak link between lateralized
processing and orienting behaviour might be detected, as
is the case for the dichotomous listening paradigm.
Regarding the application of the head-turning paradigm,
however, the contribution of other factors may mask orienting biases related to the stimulus material renders the
use of the orienting assay for determining lateralized
processing of sounds questionable at best. The further use
of this paradigm to uncover lateralized processing of
sounds is therefore discouraged.

Conclusion
We found no contingency between lateralized processing
of sounds and orienting biases. Overall, the participants
revealed a tendency to turn left in the naturalistic behav-

Page 5 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

ioural experiments; this tendency was slightly stronger in
German subjects. A comparison with the response bias in
the fMRI experiments, where subjects revealed a slight
bias to the right in a sound localization task, indicates that
various factors such as task instructions and the experimental setting may have an effect on orienting biases. Our
results – as well as the inconsistent orienting biases found
in different animal species – suggest that the orienting
assay applied in naturalistic settings should be used with
caution. In particular, it does not seem to be possible to
infer lateralized processing from orienting biases alone
[9,17,18]. Unfortunately, therefore, the further use of this
paradigm to uncover hemispheric lateralization cannot be
recommended.

Methods
Naturalistic Behavioural Experiments
Stimuli
We used two different types of acoustic stimuli: spoken
words ('Speech') [see Additional file 2] and non-linguistic
artificially produced sounds ('Artificial') [see Additional
file 3]. In Germany, the recorded spoken words were
"Geh" (go!), "Komm" (come!), "Rad" (wheel), and
"Kinn" (chin); in the UK we used "go!", "come!", "rat",
"chin" and "Kinn" (from the German stimuli because this
sounded similar to 'kin'). Half of the human utterances in
each category were produced by two female speakers and
the other half by two male speakers. The artificial sounds
consisted of a total of 12 artificial stimuli generated from
natural non-biological sounds which were distorted such
that they could no longer be attributed to natural events.
Stimuli were taken from a subset of sounds employed in
a previous study [30]. These stimuli were produced by cutting and distorting portions of longer commercial sound
files, with a duration of 200 ms including 10 ms rise and
40 ms fall time. Based on the results of a subjective rating
study, only sounds which were classified as being unidentifiable by fifteen subjects were used in the present study
(for further details, see [30]). All auditory stimuli were
normalized for sound pressure level. The average stimulus
duration was 330 ± 135 ms (mean ± SD).
Procedure
Participants for this study were chosen opportunistically,
depending on their posture. Subjects had to stand still in
a straight, upright posture at the time of the trial. In addition, subjects' heads were required to be straight with
respect to the body on the horizontal axis (i.e. looking
neither left nor right), while they could be looking up or
down (i.e. bent on the vertical axis) as this should have no
effect on preference to turn either right or left. Experiments in Germany were conducted in Göttingen; those in
the UK in London and Cambridge.

http://www.biomedcentral.com/1471-2202/10/14

Two experimenters participated in each trial. The first used
a PalmOS handheld (Tungsten E2, Palm Inc., Wokingham
Berkshire, UK) to record information about each trial. The
data Pendragon Forms mobile software was used to create
a list of information to be recorded in a database for each
trial. A second experimenter (the initiator) approached
each subject from behind. The initiator placed herself
with portable speakers (Travelsound 400, Creative, Dublin, Ireland or SP-106 Travel Speakers, Tesco Technika,
Hertfordshire, England) and an mp3 (Zen Nomad Jukebox, Creative, Dublin, Ireland) player directly behind the
subject at approximately 1 m distance. The height of the
presentation was approximately 0.2–0.5 m below the ear
level of the listener, so that the presentation could be
done without being too conspicuous. Then the recorded
sound was played back at a peak sound pressure level of
76.7 ± 3.9 dB re 20 μPa measured at a distance of 1 m (SPL
level meter Rion NL-05, fast mode). If the subject did not
respond immediately, the sound was produced again, up
to a maximum of three times after which the trial was
aborted if the subject had not responded. 62% of the participants responded in the first trial, 30% and the second,
and 8% of the subjects in the third trial. There was no difference in turning biases in relation to the number of presentations (χ2 = 0.83, N = 224, df = 2). Importantly, the
initiator was instructed to playback sounds from a position directly behind the subject but was blind to the purpose of the study and also to the specific stimulus category
played back in a given trial. Following each successful test,
the subject was approached by both experimenters. The
purpose of the experiment was explained and subject's
handedness assessed. Further, the time spent living in the
respective country was requested. People who had been
living less than 10 years in the country were excluded from
the analysis. The following information was recorded on
the PalmOS handheld: the sound used or produced, the
number of times played (up to a maximum of 3), the reaction orientation (right or left) for each subject, and the
subject's gender and handedness. Since we obtained too
few data for a meaningful analysis of left handed people,
these data were discarded. The final sample consisted of
224 successful trials, each with a different individual. All
people tested consented to the use of their data.
Statistical Analysis
We used Binomial tests to examine orienting biases
within the stimulus categories separately for each population (country). Results were corrected for multiple testing
using a sequential Bonferroni correction (Step-Up Hochberg). In addition, a multinomial regression was used to
test for the effects of country, stimulus category, and gender as well as the interactions between the main factors.
All tests were calculated using SPSS 15.0.

Page 6 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

FMRI Experiment
Participants
22 right-handed, healthy young volunteers (10 female,
aged from 22 to 34 years, mean age = 25.95 years) participated in the study. Handedness was assessed by the Edinburgh Handedness Inventory (Oldfield, 1971). Only
subjects with normal hearing acuity were included. After
being informed about potential risks and screened by a
physician of the institution, subjects gave informed consent before participating. The experimental standards
were approved by the local ethics committee of the University of Leipzig. Data were handled anonymously.
Stimuli
In addition to the stimuli described above (Speech and
Artificial sounds), we also used time-reversed spoken
words (Reverse) and non-linguistic human utterances as
part of a separate investigation. In the Reverse class the
same stimuli as in the Speech class were used but playedback in reverse. To further test whether hemispheric lateralization concerns species-specificity or acoustic features,
we included a Human Sound class that comprised coughing, harrumphing, humming, and clicking one's tongue,
i.e. four different non-linguistic species-specific sounds.
Data from these conditions will not be considered further
in the present paper. Half of the human utterances of all
three classes were produced by two female speakers and
the other half by two male speakers.
Presentation
The experiment comprised of four conditions (Speech,
Voice, Reverse, Artificial) and a visual control (Figure 3).
Conditions were presented in randomized order (mixed
trial design), and trial order differed for each subject.
Within each trial of each condition, stimulation lasted
350 ms and was preceded by a variable gap (jittering) of
either 830 ms, 1103 ms, 1376 ms, or 1649 ms. Stimulation was followed by a question mark presented after
2000 ms. This stimulus-onset-asynchrony was required in
order to analyze brain activity without effects of the motor
response. The question mark signalled the beginning of
the response period which lasted 2000 ms at maximum;

http://www.biomedcentral.com/1471-2202/10/14

earlier responses aborted the question mark presentation.
The next trial started after a variable interval (2350 to
3170 ms after the onset of the question mark, dependent
on the jittering at the beginning of the trial). The trialonset-asynchrony was 6 seconds. Except for the time during which the question mark was presented, the screen
showed a fixation cross of 10 mm width and 10 mm
height.
For all auditory conditions, sounds were presented as if
coming from different locations in space. Five virtual
sources were simulated by introducing different interaural time differences (ITDs): 0° (i.e. no ITD), 0.1 ms left
(right) channel precedence (~10° deviance), or 0.2 ms left
(right) channel precedence (~20° deviance). Within each
auditory condition, the probability for a sound to be presented from 0° was 0.31; the probability for any other
source was 0.167. In a visual control condition, a second
cross was presented in addition to the original fixation
cross 0.86° (sign centre) either to its right or to its left side.
Stimulus presentation time was identical to that in the
auditory conditions.
Three-hundred-twenty trials were presented overall,
including 20 trials for the control condition and 20 empty
trials (null-events). Among auditory conditions the
number of trials differed such that hearing biological
sounds (Speech, Voice, and Reverse) and non-biological
sounds (Artificial) was equally probable, and, when hearing biological sounds, hearing linguistic (Speech) and
non-linguistic (Voice, Reverse) sounds was equally probable, and when hearing non-linguistic sounds, hearing
familiar/meaningful (Voice) and unfamiliar/meaningless
(Reverse) sounds was equally probable. Accordingly, we
presented 70 trials for Speech, 35 trials for Voice, 35 trials
for Reverse, and 140 trials for Artificial.
Task Instructions
For the auditory conditions, participants were instructed
to indicate whether they heard the stimulus coming rather
from the right (pressing the right-hand button) or from
the left (pressing the left-hand button). Participants were

Figure 3
Presentation of stimuli in the fMRI Experiment
Presentation of stimuli in the fMRI Experiment. All trials followed the same temporal schema. Brain correlates were
analyzed in an event-related design, time locked to stimulus onset. Performance was assessed by a forced choice after response
cue presentation (question mark).

Page 7 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

told that some stimuli were more difficult to locate than
others, but they were naïve about the occurrence of stimuli coming from the 0° position. Participants were asked
to deliver their response as fast as possible when the question mark appeared. For the visual control condition, participants were asked to indicate whether the second cross
appeared left or right from the fixation cross by pressing
the corresponding response button. Participants were
instructed before the fMRI experiment.

http://www.biomedcentral.com/1471-2202/10/14

Authors' contributions
JF and CT conceived the study, analyzed the behavioural
data and wrote the manuscript, MD and AP conducted the
behavioural experiments, JF, CT and RIS planned the fMRI
experiments, RIS conducted the fMRI experiments and
analyzed the fMRI data, DYC and RR provided technical
expertise and logistical support. All authors commented
on the manuscript.

Additional material
Data Acquisition
In the MRI session, subjects were supine on the scanner
bed with their right and left index finger positioned on the
response buttons. In order to prevent postural adjustments, the subject's arms and hands were carefully stabilized by tape. In addition, form fitting cushions were used
to prevent arm, hand and head motion. Participants were
provided with earplugs (Bilsom model 303) to attenuate
scanner noise (up to 41.8 dB). The auditory stimuli were
presented via non-air tubes and through magnetic resonance-compatible electrostatic headphones ('Commander XG', Resonance Technology) which attenuates
about 30 dB of gradient noise. Imaging was performed at
3T on a Bruker Medspec 30/100 system equipped with the
standard bird cage head coil. Twelve axial slices (field of
view 192 mm, 64 by 64 pixel matrix, thickness 3 mm,
spacing 1 mm) parallel to the AC-PC plane were acquired
using a single-shot gradient EPI sequence (TE = 30 ms, flip
angle 90°, TR = 2000 ms) sensitive to BOLD contrast.
Acquisition of the slices within the TR was arranged so
that the slices were all rapidly acquired during 830 ms followed by a "silent" period of no acquisition (1170 ms) to
complete the TR. This protocol, sometimes called
bunched-early sequence, was used in order to present
auditory stimuli without the gradient noise and so to
enhance auditory perception. A set of 2D anatomical
images was acquired for each subject immediately prior to
the functional experiment, using a MDEFT sequence (256
× 256 pixel matrix). In a separate session, high resolution
whole brain images were acquired from each subject to
improve the localization of activation foci using a T1weighted 3D segmented MDEFT sequence covering the
whole brain.
Data Analysis
To assess whether responses to centrally presented stimuli
differed in relation to the stimulus class, we calculated a
repeated measures ANOVA of the proportion of right
responses with stimulus as two-level within-subject factor
(Speech, Artificial) and gender as between-subjects factor.
The imaging data were processed using the software package LIPSIA [31]. This software package contains tools for
pre-processing, co-registration, statistical evaluation, and
visualization of fMRI data [see Additional file 4].

Additional file 1
Additional behavioural experiment. This file contains the procedure and
results of an additional sound localization experiment.
Click here for file
[http://www.biomedcentral.com/content/supplementary/14712202-10-14-S1.doc]

Additional file 2
Speech samples. The file contains examples of speech stimuli used in the
experiments. The sampling frequency is 44.1 kHz.
Click here for file
[http://www.biomedcentral.com/content/supplementary/14712202-10-14-S2.wav]

Additional file 3
Artificial sound samples. The file contains examples of artificial sound
stimuli used in the experiments. The sampling frequency is 44.1 kHz.
Click here for file
[http://www.biomedcentral.com/content/supplementary/14712202-10-14-S3.wav]

Additional file 4
Analysis of fMRI data. The file contains the specifics of the fMRI data
analysis.
Click here for file
[http://www.biomedcentral.com/content/supplementary/14712202-10-14-S4.doc]

Acknowledgements
We would like to thank Oliver Heller for the stimulus material and programming, Kurt Hammerschmidt for many stimulating discussions and helpful comments on the manuscript, Gaby Lohmann and Karsten Müller for
support in MRI statistics, and Oliver Heller, Anika Dreier, Jeannette Freynik, Tina Jensen, Jakob von Herder, Matthias Klapproth, Nicolai Niessen,
and Lucy Cheke for experimental assistance. The study was supported
through the German Science foundation DFG Cr 43/13-2 and Die Junge
Akademie.

References
1.
2.
3.

Harrington A: Unfinished business: Models of Laterality in the
19th century. In Brain Asymmetry Edited by: Davidson RJ, Hugdahl
K. Cambridge, MA: MIT Press; 1995:3-27.
Fitch RH, Miller S, Tallal P: Neurobiology of speech perception.
Ann Rev Neurosci 1997, 20:331-353.
Friederici A, Alter K: Lateralization of auditory language functions: A dynamic dual pathway model. Brain Lang 2004,
89:267-276.

Page 8 of 9
(page number not for citation purposes)

BMC Neuroscience 2009, 10:14

4.
5.

6.
7.
8.
9.

10.

11.
12.

13.
14.
15.
16.

17.
18.

19.
20.

21.
22.
23.

24.

25.

Rogers LJ, Andrew RJ: Comparative Vertebrate Lateralization New York:
Cambridge University Press; 2002.
Hopkins WD, Fernandez-Carriba S: Laterality in communicative
behaviors in nonhuman primates: A critical analysis. In Comparative Vertebrate Lateralization Edited by: Rogers LJ, Andrews RD.
Oxford: Oxford University Press; 2002:445-479.
Vallortigara G, Rogers LJ: Survival with an asymmetric brain:
advantages and disadvantages of cerebral lateralization.
Behav Brain Sci 2005, 28:575-633.
Petersen MR, Beecher MD, Zoloth SR, Moody DB, Stebbins WC:
Neural lateralization of species-specific vocalizations by Japanese macaques (Macaca fuscata). Science 1978, 202:324-327.
Poremba A, Malloy M, Saunders RC, Carson RE, Herscovitch P,
Mishkin M: Species-specific calls evoke asymmetric activity in
the monkey's temporal poles. Nature 2004, 427:448-451.
Hauser MD, Andersson K: Left hemisphere dominance for
processing vocalizations in adult, but not infant, rhesus monkeys: field experiments.
Proc Nat Acad Sci USA 1994,
91:3946-3948.
Weiss D, Ghazanfar AA, Miller CT, Hauser MD: Specialized
processing of primate facial and vocal expressions: Evidence
for cerebral asymmetries. In Cerebral Vertebrate Lateralization
Edited by: Rogers LJ, Andrew RJ. New York: Cambridge University
Press; 2002.
Hauser MD, Agnetta B: Orienting asymmetries in rhesus monkeys: The effect of time-domain changes on acoustic perception. Anim Behav 1998, 56:41-47.
Ghazanfar AA, Smith-Rohrberg D, Hauser MD: The role of temporal cues in rhesus monkey vocal recognition: Orienting
asymmetries to reversed calls.
Brain Behav Evol 2001,
58:163-172.
Pohl P: Central auditory processing. V. Ear advantages for
acoustic stimuli in baboons. Brain Lang 1983, 20:44-53.
Pohl P: Ear advantages for temporal resolution in baboons.
Brain Cognition 1984, 3:438-444.
Teufel CR, Hammerschmidt K, Fischer J: Lack of orienting asymmetries in Barbary macaques: implications for studies of lateralized auditory processing. Anim Behav 2007, 73:249-255.
Gil-Da-Costa R, Hauser MD: Vervet monkeys and humans show
brain asymmetries for processing conspecific vocalizations,
but with opposite patterns of laterality. Proceedings of the Royal
society of London 2006:1-6.
Scheumann M, Zimmermann E: Sex-specific asymmetries in
communication sound perception are not related to hand
preference in an early primate. BMC Biology 2008, 6:3.
Böye M, Güntürkün O, Vauclair J: Right ear advantage for conspecific calls in adults and subadults, but not infants, California sea lions (Zalophus californianus): hemispheric
specialization for communication?
Eur J Neurosci 2005,
21:1727-1732.
Siniscalchi M, Quaranta A, Rogers LJ: Hemispheric specialization
in dogs for processing different acoustic stimuli. PLoS One
2008, 3:e3349.
Mattingley JB, Berberovic N, Corben L, Slavin MJ, Nicholls MER, Bradshawd JL: The greyscales task: a perceptual measure of attentional bias following unilateral hemispheric damage.
Neuropsychologia 2004, 42:387-394.
Tomer R: Attentional bias as trait: Correlations with novelty
seeking. Neuropsychologia 2008, 46:2064-2070.
Kaiser J, Lutzenberger W, Preissl H, Ackermann H, Birbaumer N:
Right-hemisphere dominance for the processing of soundsource lateralization. J Neurosci 2000, 20:6631-6639.
Krumbholz K, Schönwiesner M, von Cramon DY, Rübsamen R, Shah
NJ, Zilles K, Fink GR: Representation of interaural temporal
information from left and right auditory space in the human
planum temporale and inferior parietal lobe. Cerebral Cortex
2005, 15:317-324.
Schönwiesner M, Krumbholz K, Rübsamen R, Fink GR, von Cramon
DY: Hemispheric asymmetry for auditory processing in the
human auditory brain stem, thalamus, and cortex. Cerebral
Cortex 2007, 17:492-499.
Mesulam MM: Spatial attention and neglect: parietal, frontal
and cingulate contributions to the mental representation
and attentional targeting of salient extrapersonal events. Phil
Trans Roy Soc London B 1999, 354:1325-1346.

http://www.biomedcentral.com/1471-2202/10/14

26.
27.
28.
29.
30.
31.

Karnath HO, Dieterich M: Spatial neglect – a vestibular disorder? Brain 2006, 129:293-305.
Peters M: Handedness and its relation to other indices of cerebral lateralization. In Brain Asymmetry Edited by: Davidson RJ,
Hugdahl K. Cambridge, MA: MIT Press; 1995:183-214.
Gusnard DA, Raichle ME, Raichle DA: Searching for a baseline:
functional imaging and the resting human brain. Nat Rev Neurosc 2001, 2:685-694.
Raichle ME, MacLeod AM, Snyder AZ, Powers WJ, Gusnard DA, Shulman GL: A default mode of brain function. Proc Nat Acad Sci USA
2001, 98:676-682.
Mecklinger A, Opitz B, Friederici A: Semantic aspects of novelty
detection in humans. Neurosci Lett 1997, 235:65-68.
Lohmann G, Müller K, Bosch V, Mentzel H, Hessler S, Chen L, Zysset
S, von Cramon DY: LIPSIA – a new software system for the
evaluation of functional magnetic resonance images of the
human brain. Comp Med Imag Graphics 2001, 25:449-457.

Publish with Bio Med Central and every
scientist can read your work free of charge
"BioMed Central will be the most significant development for
disseminating the results of biomedical researc h in our lifetime."
Sir Paul Nurse, Cancer Research UK

Your research papers will be:
available free of charge to the entire biomedical community
peer reviewed and published immediately upon acceptance
cited in PubMed and archived on PubMed Central
yours — you keep the copyright

BioMedcentral

Submit your manuscript here:
http://www.biomedcentral.com/info/publishing_adv.asp

Page 9 of 9
(page number not for citation purposes)

</pre>
</body>
</html>
